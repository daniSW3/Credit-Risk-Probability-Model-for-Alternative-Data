{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ced5dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (95662, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionId</th>\n",
       "      <th>BatchId</th>\n",
       "      <th>AccountId</th>\n",
       "      <th>SubscriptionId</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CurrencyCode</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>ProviderId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>ChannelId</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Value</th>\n",
       "      <th>TransactionStartTime</th>\n",
       "      <th>PricingStrategy</th>\n",
       "      <th>FraudResult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TransactionId_76871</td>\n",
       "      <td>BatchId_36123</td>\n",
       "      <td>AccountId_3957</td>\n",
       "      <td>SubscriptionId_887</td>\n",
       "      <td>CustomerId_4406</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>ProductId_10</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2018-11-15T02:18:49Z</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TransactionId_73770</td>\n",
       "      <td>BatchId_15642</td>\n",
       "      <td>AccountId_4841</td>\n",
       "      <td>SubscriptionId_3829</td>\n",
       "      <td>CustomerId_4406</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_4</td>\n",
       "      <td>ProductId_6</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>ChannelId_2</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2018-11-15T02:19:08Z</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TransactionId_26203</td>\n",
       "      <td>BatchId_53941</td>\n",
       "      <td>AccountId_4229</td>\n",
       "      <td>SubscriptionId_222</td>\n",
       "      <td>CustomerId_4683</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>ProductId_1</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500</td>\n",
       "      <td>2018-11-15T02:44:21Z</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TransactionId_380</td>\n",
       "      <td>BatchId_102363</td>\n",
       "      <td>AccountId_648</td>\n",
       "      <td>SubscriptionId_2185</td>\n",
       "      <td>CustomerId_988</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_1</td>\n",
       "      <td>ProductId_21</td>\n",
       "      <td>utility_bill</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>21800</td>\n",
       "      <td>2018-11-15T03:32:55Z</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TransactionId_28195</td>\n",
       "      <td>BatchId_38780</td>\n",
       "      <td>AccountId_4841</td>\n",
       "      <td>SubscriptionId_3829</td>\n",
       "      <td>CustomerId_988</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_4</td>\n",
       "      <td>ProductId_6</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>ChannelId_2</td>\n",
       "      <td>-644.0</td>\n",
       "      <td>644</td>\n",
       "      <td>2018-11-15T03:34:21Z</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TransactionId         BatchId       AccountId       SubscriptionId  \\\n",
       "0  TransactionId_76871   BatchId_36123  AccountId_3957   SubscriptionId_887   \n",
       "1  TransactionId_73770   BatchId_15642  AccountId_4841  SubscriptionId_3829   \n",
       "2  TransactionId_26203   BatchId_53941  AccountId_4229   SubscriptionId_222   \n",
       "3    TransactionId_380  BatchId_102363   AccountId_648  SubscriptionId_2185   \n",
       "4  TransactionId_28195   BatchId_38780  AccountId_4841  SubscriptionId_3829   \n",
       "\n",
       "        CustomerId CurrencyCode  CountryCode    ProviderId     ProductId  \\\n",
       "0  CustomerId_4406          UGX          256  ProviderId_6  ProductId_10   \n",
       "1  CustomerId_4406          UGX          256  ProviderId_4   ProductId_6   \n",
       "2  CustomerId_4683          UGX          256  ProviderId_6   ProductId_1   \n",
       "3   CustomerId_988          UGX          256  ProviderId_1  ProductId_21   \n",
       "4   CustomerId_988          UGX          256  ProviderId_4   ProductId_6   \n",
       "\n",
       "      ProductCategory    ChannelId   Amount  Value  TransactionStartTime  \\\n",
       "0             airtime  ChannelId_3   1000.0   1000  2018-11-15T02:18:49Z   \n",
       "1  financial_services  ChannelId_2    -20.0     20  2018-11-15T02:19:08Z   \n",
       "2             airtime  ChannelId_3    500.0    500  2018-11-15T02:44:21Z   \n",
       "3        utility_bill  ChannelId_3  20000.0  21800  2018-11-15T03:32:55Z   \n",
       "4  financial_services  ChannelId_2   -644.0    644  2018-11-15T03:34:21Z   \n",
       "\n",
       "   PricingStrategy  FraudResult  \n",
       "0                2            0  \n",
       "1                2            0  \n",
       "2                2            0  \n",
       "3                2            0  \n",
       "4                2            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Engineering Pipeline (Jupyter Notebook Version)\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    LabelEncoder,\n",
    "    FunctionTransformer\n",
    ")\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from xverse.transformer import MonotonicBinning\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the data\n",
    "data_path = r\"C:\\Users\\Daniel.Temesgen\\Desktop\\KIAM-Rsc\\week5\\Data\\data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Display basic info\n",
    "print(\"Data shape:\", data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b8bcbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Data shape: (95662, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionId</th>\n",
       "      <th>BatchId</th>\n",
       "      <th>AccountId</th>\n",
       "      <th>SubscriptionId</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CurrencyCode</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>ProviderId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>ChannelId</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Value</th>\n",
       "      <th>TransactionStartTime</th>\n",
       "      <th>PricingStrategy</th>\n",
       "      <th>FraudResult</th>\n",
       "      <th>Total_Transaction_Amount</th>\n",
       "      <th>Average_Transaction_Amount</th>\n",
       "      <th>Transaction_Count</th>\n",
       "      <th>Std_Transaction_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TransactionId_76871</td>\n",
       "      <td>BatchId_36123</td>\n",
       "      <td>AccountId_3957</td>\n",
       "      <td>SubscriptionId_887</td>\n",
       "      <td>CustomerId_4406</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>ProductId_10</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2018-11-15T02:18:49Z</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>109921.75</td>\n",
       "      <td>923.712185</td>\n",
       "      <td>119</td>\n",
       "      <td>3042.294251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TransactionId_73770</td>\n",
       "      <td>BatchId_15642</td>\n",
       "      <td>AccountId_4841</td>\n",
       "      <td>SubscriptionId_3829</td>\n",
       "      <td>CustomerId_4406</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_4</td>\n",
       "      <td>ProductId_6</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>ChannelId_2</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2018-11-15T02:19:08Z</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>109921.75</td>\n",
       "      <td>923.712185</td>\n",
       "      <td>119</td>\n",
       "      <td>3042.294251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TransactionId_26203</td>\n",
       "      <td>BatchId_53941</td>\n",
       "      <td>AccountId_4229</td>\n",
       "      <td>SubscriptionId_222</td>\n",
       "      <td>CustomerId_4683</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>ProductId_1</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500</td>\n",
       "      <td>2018-11-15T02:44:21Z</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TransactionId_380</td>\n",
       "      <td>BatchId_102363</td>\n",
       "      <td>AccountId_648</td>\n",
       "      <td>SubscriptionId_2185</td>\n",
       "      <td>CustomerId_988</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_1</td>\n",
       "      <td>ProductId_21</td>\n",
       "      <td>utility_bill</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>21800</td>\n",
       "      <td>2018-11-15T03:32:55Z</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>228727.20</td>\n",
       "      <td>6019.136842</td>\n",
       "      <td>38</td>\n",
       "      <td>17169.241610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TransactionId_28195</td>\n",
       "      <td>BatchId_38780</td>\n",
       "      <td>AccountId_4841</td>\n",
       "      <td>SubscriptionId_3829</td>\n",
       "      <td>CustomerId_988</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_4</td>\n",
       "      <td>ProductId_6</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>ChannelId_2</td>\n",
       "      <td>-644.0</td>\n",
       "      <td>644</td>\n",
       "      <td>2018-11-15T03:34:21Z</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>228727.20</td>\n",
       "      <td>6019.136842</td>\n",
       "      <td>38</td>\n",
       "      <td>17169.241610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TransactionId         BatchId       AccountId       SubscriptionId  \\\n",
       "0  TransactionId_76871   BatchId_36123  AccountId_3957   SubscriptionId_887   \n",
       "1  TransactionId_73770   BatchId_15642  AccountId_4841  SubscriptionId_3829   \n",
       "2  TransactionId_26203   BatchId_53941  AccountId_4229   SubscriptionId_222   \n",
       "3    TransactionId_380  BatchId_102363   AccountId_648  SubscriptionId_2185   \n",
       "4  TransactionId_28195   BatchId_38780  AccountId_4841  SubscriptionId_3829   \n",
       "\n",
       "        CustomerId CurrencyCode  CountryCode    ProviderId     ProductId  \\\n",
       "0  CustomerId_4406          UGX          256  ProviderId_6  ProductId_10   \n",
       "1  CustomerId_4406          UGX          256  ProviderId_4   ProductId_6   \n",
       "2  CustomerId_4683          UGX          256  ProviderId_6   ProductId_1   \n",
       "3   CustomerId_988          UGX          256  ProviderId_1  ProductId_21   \n",
       "4   CustomerId_988          UGX          256  ProviderId_4   ProductId_6   \n",
       "\n",
       "      ProductCategory    ChannelId   Amount  Value  TransactionStartTime  \\\n",
       "0             airtime  ChannelId_3   1000.0   1000  2018-11-15T02:18:49Z   \n",
       "1  financial_services  ChannelId_2    -20.0     20  2018-11-15T02:19:08Z   \n",
       "2             airtime  ChannelId_3    500.0    500  2018-11-15T02:44:21Z   \n",
       "3        utility_bill  ChannelId_3  20000.0  21800  2018-11-15T03:32:55Z   \n",
       "4  financial_services  ChannelId_2   -644.0    644  2018-11-15T03:34:21Z   \n",
       "\n",
       "   PricingStrategy  FraudResult  Total_Transaction_Amount  \\\n",
       "0                2            0                 109921.75   \n",
       "1                2            0                 109921.75   \n",
       "2                2            0                   1000.00   \n",
       "3                2            0                 228727.20   \n",
       "4                2            0                 228727.20   \n",
       "\n",
       "   Average_Transaction_Amount  Transaction_Count  Std_Transaction_Amount  \n",
       "0                  923.712185                119             3042.294251  \n",
       "1                  923.712185                119             3042.294251  \n",
       "2                  500.000000                  2                0.000000  \n",
       "3                 6019.136842                 38            17169.241610  \n",
       "4                 6019.136842                 38            17169.241610  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate features per customer\n",
    "aggregate_features = data.groupby('CustomerId').agg({\n",
    "    'Amount': [\n",
    "        ('Total_Transaction_Amount', 'sum'),\n",
    "        ('Average_Transaction_Amount', 'mean'),\n",
    "        ('Transaction_Count', 'count'),\n",
    "        ('Std_Transaction_Amount', 'std')\n",
    "    ]\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "aggregate_features.columns = ['CustomerId', 'Total_Transaction_Amount', \n",
    "                            'Average_Transaction_Amount', 'Transaction_Count', \n",
    "                            'Std_Transaction_Amount']\n",
    "\n",
    "# Merge aggregate features back to original dataset\n",
    "data_enhanced = data.merge(aggregate_features, on='CustomerId', how='left')\n",
    "\n",
    "# Display the first few rows of enhanced dataset\n",
    "print(\"Enhanced Data shape:\", data_enhanced.shape)\n",
    "data_enhanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "115cf11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with extracted features shape: (95662, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionId</th>\n",
       "      <th>TransactionStartTime</th>\n",
       "      <th>Transaction_Hour</th>\n",
       "      <th>Transaction_Day</th>\n",
       "      <th>Transaction_Month</th>\n",
       "      <th>Transaction_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TransactionId_76871</td>\n",
       "      <td>2018-11-15 02:18:49+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TransactionId_73770</td>\n",
       "      <td>2018-11-15 02:19:08+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TransactionId_26203</td>\n",
       "      <td>2018-11-15 02:44:21+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TransactionId_380</td>\n",
       "      <td>2018-11-15 03:32:55+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TransactionId_28195</td>\n",
       "      <td>2018-11-15 03:34:21+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TransactionId      TransactionStartTime  Transaction_Hour  \\\n",
       "0  TransactionId_76871 2018-11-15 02:18:49+00:00                 2   \n",
       "1  TransactionId_73770 2018-11-15 02:19:08+00:00                 2   \n",
       "2  TransactionId_26203 2018-11-15 02:44:21+00:00                 2   \n",
       "3    TransactionId_380 2018-11-15 03:32:55+00:00                 3   \n",
       "4  TransactionId_28195 2018-11-15 03:34:21+00:00                 3   \n",
       "\n",
       "   Transaction_Day  Transaction_Month  Transaction_Year  \n",
       "0               15                 11              2018  \n",
       "1               15                 11              2018  \n",
       "2               15                 11              2018  \n",
       "3               15                 11              2018  \n",
       "4               15                 11              2018  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert TransactionStartTime to datetime\n",
    "data_enhanced['TransactionStartTime'] = pd.to_datetime(data_enhanced['TransactionStartTime'])\n",
    "\n",
    "# Extract temporal features\n",
    "data_enhanced['Transaction_Hour'] = data_enhanced['TransactionStartTime'].dt.hour\n",
    "data_enhanced['Transaction_Day'] = data_enhanced['TransactionStartTime'].dt.day\n",
    "data_enhanced['Transaction_Month'] = data_enhanced['TransactionStartTime'].dt.month\n",
    "data_enhanced['Transaction_Year'] = data_enhanced['TransactionStartTime'].dt.year\n",
    "\n",
    "# Display the first few rows with new features\n",
    "print(\"Data with extracted features shape:\", data_enhanced.shape)\n",
    "data_enhanced[['TransactionId', 'TransactionStartTime', 'Transaction_Hour', \n",
    "               'Transaction_Day', 'Transaction_Month', 'Transaction_Year']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a27d0306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with encoded features shape: (95662, 65)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "      <th>Value</th>\n",
       "      <th>TransactionStartTime</th>\n",
       "      <th>FraudResult</th>\n",
       "      <th>Total_Transaction_Amount</th>\n",
       "      <th>Average_Transaction_Amount</th>\n",
       "      <th>Transaction_Count</th>\n",
       "      <th>Std_Transaction_Amount</th>\n",
       "      <th>Transaction_Hour</th>\n",
       "      <th>Transaction_Day</th>\n",
       "      <th>...</th>\n",
       "      <th>ProductCategory_tv</th>\n",
       "      <th>ProductCategory_utility_bill</th>\n",
       "      <th>ChannelId_ChannelId_1</th>\n",
       "      <th>ChannelId_ChannelId_2</th>\n",
       "      <th>ChannelId_ChannelId_3</th>\n",
       "      <th>ChannelId_ChannelId_5</th>\n",
       "      <th>PricingStrategy_0</th>\n",
       "      <th>PricingStrategy_1</th>\n",
       "      <th>PricingStrategy_2</th>\n",
       "      <th>PricingStrategy_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2018-11-15 02:18:49+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>109921.75</td>\n",
       "      <td>923.712185</td>\n",
       "      <td>119</td>\n",
       "      <td>3042.294251</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2018-11-15 02:19:08+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>109921.75</td>\n",
       "      <td>923.712185</td>\n",
       "      <td>119</td>\n",
       "      <td>3042.294251</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500.0</td>\n",
       "      <td>500</td>\n",
       "      <td>2018-11-15 02:44:21+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>21800</td>\n",
       "      <td>2018-11-15 03:32:55+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>228727.20</td>\n",
       "      <td>6019.136842</td>\n",
       "      <td>38</td>\n",
       "      <td>17169.241610</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-644.0</td>\n",
       "      <td>644</td>\n",
       "      <td>2018-11-15 03:34:21+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>228727.20</td>\n",
       "      <td>6019.136842</td>\n",
       "      <td>38</td>\n",
       "      <td>17169.241610</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Amount  Value      TransactionStartTime  FraudResult  \\\n",
       "0   1000.0   1000 2018-11-15 02:18:49+00:00            0   \n",
       "1    -20.0     20 2018-11-15 02:19:08+00:00            0   \n",
       "2    500.0    500 2018-11-15 02:44:21+00:00            0   \n",
       "3  20000.0  21800 2018-11-15 03:32:55+00:00            0   \n",
       "4   -644.0    644 2018-11-15 03:34:21+00:00            0   \n",
       "\n",
       "   Total_Transaction_Amount  Average_Transaction_Amount  Transaction_Count  \\\n",
       "0                 109921.75                  923.712185                119   \n",
       "1                 109921.75                  923.712185                119   \n",
       "2                   1000.00                  500.000000                  2   \n",
       "3                 228727.20                 6019.136842                 38   \n",
       "4                 228727.20                 6019.136842                 38   \n",
       "\n",
       "   Std_Transaction_Amount  Transaction_Hour  Transaction_Day  ...  \\\n",
       "0             3042.294251                 2               15  ...   \n",
       "1             3042.294251                 2               15  ...   \n",
       "2                0.000000                 2               15  ...   \n",
       "3            17169.241610                 3               15  ...   \n",
       "4            17169.241610                 3               15  ...   \n",
       "\n",
       "   ProductCategory_tv  ProductCategory_utility_bill  ChannelId_ChannelId_1  \\\n",
       "0                 0.0                           0.0                    0.0   \n",
       "1                 0.0                           0.0                    0.0   \n",
       "2                 0.0                           0.0                    0.0   \n",
       "3                 0.0                           1.0                    0.0   \n",
       "4                 0.0                           0.0                    0.0   \n",
       "\n",
       "   ChannelId_ChannelId_2  ChannelId_ChannelId_3  ChannelId_ChannelId_5  \\\n",
       "0                    0.0                    1.0                    0.0   \n",
       "1                    1.0                    0.0                    0.0   \n",
       "2                    0.0                    1.0                    0.0   \n",
       "3                    0.0                    1.0                    0.0   \n",
       "4                    1.0                    0.0                    0.0   \n",
       "\n",
       "   PricingStrategy_0  PricingStrategy_1  PricingStrategy_2  PricingStrategy_4  \n",
       "0                0.0                0.0                1.0                0.0  \n",
       "1                0.0                0.0                1.0                0.0  \n",
       "2                0.0                0.0                1.0                0.0  \n",
       "3                0.0                0.0                1.0                0.0  \n",
       "4                0.0                0.0                1.0                0.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = ['CurrencyCode', 'CountryCode', 'ProviderId', 'ProductId', \n",
    "                    'ProductCategory', 'ChannelId', 'PricingStrategy']\n",
    "\n",
    "# Apply Label Encoding to columns with high cardinality\n",
    "label_encoders = {}\n",
    "for col in ['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId']:\n",
    "    le = LabelEncoder()\n",
    "    data_enhanced[col + '_encoded'] = le.fit_transform(data_enhanced[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Apply One-Hot Encoding to other categorical columns\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "ohe_transformed = one_hot_encoder.fit_transform(data_enhanced[categorical_cols])\n",
    "ohe_df = pd.DataFrame(ohe_transformed, \n",
    "                      columns=one_hot_encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Concatenate one-hot encoded columns with the dataset\n",
    "data_encoded = pd.concat([data_enhanced, ohe_df], axis=1)\n",
    "\n",
    "# Drop original categorical columns\n",
    "data_encoded = data_encoded.drop(columns=categorical_cols + \n",
    "                               ['TransactionId', 'BatchId', 'AccountId', \n",
    "                                'SubscriptionId', 'CustomerId'])\n",
    "\n",
    "# Display the first few rows of encoded dataset\n",
    "print(\"Data with encoded features shape:\", data_encoded.shape)\n",
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f5be07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling:\n",
      " Amount                      0\n",
      "Value                       0\n",
      "TransactionStartTime        0\n",
      "FraudResult                 0\n",
      "Total_Transaction_Amount    0\n",
      "                           ..\n",
      "ChannelId_ChannelId_5       0\n",
      "PricingStrategy_0           0\n",
      "PricingStrategy_1           0\n",
      "PricingStrategy_2           0\n",
      "PricingStrategy_4           0\n",
      "Length: 65, dtype: int64\n",
      "Missing values after handling:\n",
      " Amount                      0\n",
      "Value                       0\n",
      "TransactionStartTime        0\n",
      "FraudResult                 0\n",
      "Total_Transaction_Amount    0\n",
      "                           ..\n",
      "ChannelId_ChannelId_5       0\n",
      "PricingStrategy_0           0\n",
      "PricingStrategy_1           0\n",
      "PricingStrategy_2           0\n",
      "PricingStrategy_4           0\n",
      "Length: 65, dtype: int64\n",
      "Final Data shape: (95662, 65)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "      <th>Value</th>\n",
       "      <th>TransactionStartTime</th>\n",
       "      <th>FraudResult</th>\n",
       "      <th>Total_Transaction_Amount</th>\n",
       "      <th>Average_Transaction_Amount</th>\n",
       "      <th>Transaction_Count</th>\n",
       "      <th>Std_Transaction_Amount</th>\n",
       "      <th>Transaction_Hour</th>\n",
       "      <th>Transaction_Day</th>\n",
       "      <th>...</th>\n",
       "      <th>ProductCategory_tv</th>\n",
       "      <th>ProductCategory_utility_bill</th>\n",
       "      <th>ChannelId_ChannelId_1</th>\n",
       "      <th>ChannelId_ChannelId_2</th>\n",
       "      <th>ChannelId_ChannelId_3</th>\n",
       "      <th>ChannelId_ChannelId_5</th>\n",
       "      <th>PricingStrategy_0</th>\n",
       "      <th>PricingStrategy_1</th>\n",
       "      <th>PricingStrategy_2</th>\n",
       "      <th>PricingStrategy_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2018-11-15 02:18:49+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>109921.75</td>\n",
       "      <td>923.712185</td>\n",
       "      <td>119.0</td>\n",
       "      <td>3042.294251</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2018-11-15 02:19:08+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>109921.75</td>\n",
       "      <td>923.712185</td>\n",
       "      <td>119.0</td>\n",
       "      <td>3042.294251</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2018-11-15 02:44:21+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>21800.0</td>\n",
       "      <td>2018-11-15 03:32:55+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>228727.20</td>\n",
       "      <td>6019.136842</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17169.241610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-644.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>2018-11-15 03:34:21+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>228727.20</td>\n",
       "      <td>6019.136842</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17169.241610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Amount    Value      TransactionStartTime  FraudResult  \\\n",
       "0   1000.0   1000.0 2018-11-15 02:18:49+00:00            0   \n",
       "1    -20.0     20.0 2018-11-15 02:19:08+00:00            0   \n",
       "2    500.0    500.0 2018-11-15 02:44:21+00:00            0   \n",
       "3  20000.0  21800.0 2018-11-15 03:32:55+00:00            0   \n",
       "4   -644.0    644.0 2018-11-15 03:34:21+00:00            0   \n",
       "\n",
       "   Total_Transaction_Amount  Average_Transaction_Amount  Transaction_Count  \\\n",
       "0                 109921.75                  923.712185              119.0   \n",
       "1                 109921.75                  923.712185              119.0   \n",
       "2                   1000.00                  500.000000                2.0   \n",
       "3                 228727.20                 6019.136842               38.0   \n",
       "4                 228727.20                 6019.136842               38.0   \n",
       "\n",
       "   Std_Transaction_Amount  Transaction_Hour  Transaction_Day  ...  \\\n",
       "0             3042.294251               2.0             15.0  ...   \n",
       "1             3042.294251               2.0             15.0  ...   \n",
       "2                0.000000               2.0             15.0  ...   \n",
       "3            17169.241610               3.0             15.0  ...   \n",
       "4            17169.241610               3.0             15.0  ...   \n",
       "\n",
       "   ProductCategory_tv  ProductCategory_utility_bill  ChannelId_ChannelId_1  \\\n",
       "0                 0.0                           0.0                    0.0   \n",
       "1                 0.0                           0.0                    0.0   \n",
       "2                 0.0                           0.0                    0.0   \n",
       "3                 0.0                           1.0                    0.0   \n",
       "4                 0.0                           0.0                    0.0   \n",
       "\n",
       "   ChannelId_ChannelId_2  ChannelId_ChannelId_3  ChannelId_ChannelId_5  \\\n",
       "0                    0.0                    1.0                    0.0   \n",
       "1                    1.0                    0.0                    0.0   \n",
       "2                    0.0                    1.0                    0.0   \n",
       "3                    0.0                    1.0                    0.0   \n",
       "4                    1.0                    0.0                    0.0   \n",
       "\n",
       "   PricingStrategy_0  PricingStrategy_1  PricingStrategy_2  PricingStrategy_4  \n",
       "0                0.0                0.0                1.0                0.0  \n",
       "1                0.0                0.0                1.0                0.0  \n",
       "2                0.0                0.0                1.0                0.0  \n",
       "3                0.0                0.0                1.0                0.0  \n",
       "4                0.0                0.0                1.0                0.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values before handling:\\n\", data_encoded.isnull().sum())\n",
    "\n",
    "# Define numerical columns for imputation (including new features)\n",
    "numerical_cols = ['Amount', 'Value', 'Total_Transaction_Amount', \n",
    "                  'Average_Transaction_Amount', 'Transaction_Count', \n",
    "                  'Std_Transaction_Amount', 'Transaction_Hour', \n",
    "                  'Transaction_Day', 'Transaction_Month', 'Transaction_Year']\n",
    "\n",
    "# Apply KNN Imputation for numerical columns\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "data_encoded[numerical_cols] = knn_imputer.fit_transform(data_encoded[numerical_cols])\n",
    "\n",
    "# Apply Simple Imputation (mode) for any remaining categorical columns\n",
    "simple_imputer = SimpleImputer(strategy='most_frequent')\n",
    "data_encoded[ohe_df.columns] = simple_imputer.fit_transform(data_encoded[ohe_df.columns])\n",
    "\n",
    "# Remove rows with any remaining missing values (if any)\n",
    "data_encoded = data_encoded.dropna()\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(\"Missing values after handling:\\n\", data_encoded.isnull().sum())\n",
    "\n",
    "# Display the first few rows of the final dataset\n",
    "print(\"Final Data shape:\", data_encoded.shape)\n",
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64c30e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with scaled features shape: (95662, 65)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "      <th>Value</th>\n",
       "      <th>Total_Transaction_Amount</th>\n",
       "      <th>Average_Transaction_Amount</th>\n",
       "      <th>Transaction_Count</th>\n",
       "      <th>Std_Transaction_Amount</th>\n",
       "      <th>Transaction_Hour</th>\n",
       "      <th>Transaction_Day</th>\n",
       "      <th>Transaction_Month</th>\n",
       "      <th>Transaction_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.046371</td>\n",
       "      <td>-0.072291</td>\n",
       "      <td>0.170118</td>\n",
       "      <td>-0.067623</td>\n",
       "      <td>-0.311831</td>\n",
       "      <td>-0.168001</td>\n",
       "      <td>-2.155530</td>\n",
       "      <td>-0.100739</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>-0.994246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.054643</td>\n",
       "      <td>-0.080251</td>\n",
       "      <td>0.170118</td>\n",
       "      <td>-0.067623</td>\n",
       "      <td>-0.311831</td>\n",
       "      <td>-0.168001</td>\n",
       "      <td>-2.155530</td>\n",
       "      <td>-0.100739</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>-0.994246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.050426</td>\n",
       "      <td>-0.076352</td>\n",
       "      <td>0.165122</td>\n",
       "      <td>-0.072568</td>\n",
       "      <td>-0.444993</td>\n",
       "      <td>-0.202150</td>\n",
       "      <td>-2.155530</td>\n",
       "      <td>-0.100739</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>-0.994246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.107717</td>\n",
       "      <td>0.096648</td>\n",
       "      <td>0.175567</td>\n",
       "      <td>-0.008155</td>\n",
       "      <td>-0.404020</td>\n",
       "      <td>-0.009434</td>\n",
       "      <td>-1.949214</td>\n",
       "      <td>-0.100739</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>-0.994246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.059704</td>\n",
       "      <td>-0.075183</td>\n",
       "      <td>0.175567</td>\n",
       "      <td>-0.008155</td>\n",
       "      <td>-0.404020</td>\n",
       "      <td>-0.009434</td>\n",
       "      <td>-1.949214</td>\n",
       "      <td>-0.100739</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>-0.994246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Amount     Value  Total_Transaction_Amount  Average_Transaction_Amount  \\\n",
       "0 -0.046371 -0.072291                  0.170118                   -0.067623   \n",
       "1 -0.054643 -0.080251                  0.170118                   -0.067623   \n",
       "2 -0.050426 -0.076352                  0.165122                   -0.072568   \n",
       "3  0.107717  0.096648                  0.175567                   -0.008155   \n",
       "4 -0.059704 -0.075183                  0.175567                   -0.008155   \n",
       "\n",
       "   Transaction_Count  Std_Transaction_Amount  Transaction_Hour  \\\n",
       "0          -0.311831               -0.168001         -2.155530   \n",
       "1          -0.311831               -0.168001         -2.155530   \n",
       "2          -0.444993               -0.202150         -2.155530   \n",
       "3          -0.404020               -0.009434         -1.949214   \n",
       "4          -0.404020               -0.009434         -1.949214   \n",
       "\n",
       "   Transaction_Day  Transaction_Month  Transaction_Year  \n",
       "0        -0.100739           0.848684         -0.994246  \n",
       "1        -0.100739           0.848684         -0.994246  \n",
       "2        -0.100739           0.848684         -0.994246  \n",
       "3        -0.100739           0.848684         -0.994246  \n",
       "4        -0.100739           0.848684         -0.994246  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define numerical columns for scaling\n",
    "numerical_cols = ['Amount', 'Value', 'Total_Transaction_Amount', \n",
    "                  'Average_Transaction_Amount', 'Transaction_Count', \n",
    "                  'Std_Transaction_Amount', 'Transaction_Hour', \n",
    "                  'Transaction_Day', 'Transaction_Month', 'Transaction_Year']\n",
    "\n",
    "# Apply Standardization\n",
    "standard_scaler = StandardScaler()\n",
    "data_encoded[numerical_cols] = standard_scaler.fit_transform(data_encoded[numerical_cols])\n",
    "\n",
    "# Optionally apply Normalization (if preferred over standardization)\n",
    "# normalizer = MinMaxScaler()\n",
    "# data_encoded[numerical_cols] = normalizer.fit_transform(data_encoded[numerical_cols])\n",
    "\n",
    "# Display the first few rows of the scaled dataset\n",
    "print(\"Data with scaled features shape:\", data_encoded.shape)\n",
    "data_encoded[numerical_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a04b68",
   "metadata": {},
   "source": [
    "#Proxy Target Variable Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e3ac0e",
   "metadata": {},
   "source": [
    "#identifying disengaged customers as high-risk proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e07be8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           CustomerId  total_transactions  negative_transactions  \\\n",
      "0        CustomerId_1                   1                      1   \n",
      "1       CustomerId_10                   1                      1   \n",
      "2     CustomerId_1001                   5                      2   \n",
      "3     CustomerId_1002                  11                      6   \n",
      "4     CustomerId_1003                   6                      2   \n",
      "...               ...                 ...                    ...   \n",
      "3737   CustomerId_992                   6                      2   \n",
      "3738   CustomerId_993                   5                      2   \n",
      "3739   CustomerId_994                 101                     40   \n",
      "3740   CustomerId_996                  17                      2   \n",
      "3741   CustomerId_998                  22                      8   \n",
      "\n",
      "      days_since_last_transaction  prop_financial_services  credit_risk  \n",
      "0                       83.716829                 0.000000            1  \n",
      "1                       83.716887                 0.000000            1  \n",
      "2                       89.070012                 0.600000            1  \n",
      "3                       25.997546                 0.545455            1  \n",
      "4                       11.789317                 0.500000            0  \n",
      "...                           ...                      ...          ...  \n",
      "3737                     4.981782                 0.500000            0  \n",
      "3738                    25.753449                 0.600000            0  \n",
      "3739                     0.947454                 0.514851            0  \n",
      "3740                    67.775660                 0.882353            1  \n",
      "3741                     0.093113                 0.363636            0  \n",
      "\n",
      "[3742 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Assuming the data is loaded into a DataFrame (replace with actual data loading if needed)\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Convert TransactionStartTime to datetime\n",
    "data['TransactionStartTime'] = pd.to_datetime(data['TransactionStartTime'])\n",
    "\n",
    "# Calculate customer-level features\n",
    "latest_date = data['TransactionStartTime'].max()\n",
    "\n",
    "customer_features = data.groupby('CustomerId').agg({\n",
    "    'TransactionId': 'count',  # Total transactions\n",
    "    'Amount': [\n",
    "        lambda x: (x < 0).sum(),  # Count of negative transactions\n",
    "        'mean'  # Average transaction amount\n",
    "    ],\n",
    "    'TransactionStartTime': lambda x: (latest_date - x.max()).total_seconds() / (24 * 3600),  # Days since last transaction\n",
    "    'ProductCategory': lambda x: (x == 'financial_services').sum() / len(x),  # Proportion of financial_services transactions\n",
    "    'FraudResult': 'max'  # Any fraud flags\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "customer_features.columns = [\n",
    "    'CustomerId', \n",
    "    'total_transactions', \n",
    "    'negative_transactions', \n",
    "    'avg_transaction_amount', \n",
    "    'days_since_last_transaction', \n",
    "    'prop_financial_services', \n",
    "    'has_fraud'\n",
    "]\n",
    "\n",
    "# Define disengagement criteria for high-risk\n",
    "def assign_credit_risk(row):\n",
    "    if (row['total_transactions'] < 2) or \\\n",
    "       (row['negative_transactions'] / row['total_transactions'] > 0.5) or \\\n",
    "       (row['days_since_last_transaction'] > 30) or \\\n",
    "       (row['prop_financial_services'] > 0.5 and row['avg_transaction_amount'] < 0) or \\\n",
    "       (row['has_fraud'] == 1):\n",
    "        return 1  # High-risk (disengaged)\n",
    "    return 0  # Low-risk\n",
    "\n",
    "# Apply the criteria\n",
    "customer_features['credit_risk'] = customer_features.apply(assign_credit_risk, axis=1)\n",
    "\n",
    "# Merge back to original data (if needed for transaction-level analysis)\n",
    "data = data.merge(customer_features[['CustomerId', 'credit_risk']], on='CustomerId', how='left')\n",
    "\n",
    "# View results\n",
    "print(customer_features[['CustomerId', 'total_transactions', 'negative_transactions', \n",
    "                        'days_since_last_transaction', 'prop_financial_services', 'credit_risk']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b4638a",
   "metadata": {},
   "source": [
    "#RFM segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae6a19ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           CustomerId  Recency  Frequency  Monetary  credit_risk\n",
      "0        CustomerId_1       -6          1  -10000.0            1\n",
      "1       CustomerId_10       -6          1  -10000.0            1\n",
      "2     CustomerId_1001       -1          5   20000.0            1\n",
      "3     CustomerId_1002      -64         11    4225.0            1\n",
      "4     CustomerId_1003      -78          6   20000.0            0\n",
      "...               ...      ...        ...       ...          ...\n",
      "3737   CustomerId_992      -85          6   20000.0            0\n",
      "3738   CustomerId_993      -64          5   20000.0            0\n",
      "3739   CustomerId_994      -89        101  543873.0            0\n",
      "3740   CustomerId_996      -22         17  139000.0            1\n",
      "3741   CustomerId_998      -90         22  100000.0            0\n",
      "\n",
      "[3742 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Provided data\n",
    "\n",
    "# Convert TransactionStartTime to datetime\n",
    "data['TransactionStartTime'] = pd.to_datetime(data['TransactionStartTime'])\n",
    "\n",
    "# Define snapshot date (day after the latest transaction)\n",
    "snapshot_date = pd.to_datetime('2018-11-16T00:00:00Z')\n",
    "\n",
    "# Calculate RFM metrics\n",
    "rfm_metrics = data.groupby('CustomerId').agg({\n",
    "    'TransactionStartTime': lambda x: (snapshot_date - x.max()).days,  # Recency: days since last transaction\n",
    "    'TransactionId': 'count',  # Frequency: number of transactions\n",
    "    'Amount': 'sum'  # Monetary: total amount\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "rfm_metrics.columns = ['CustomerId', 'Recency', 'Frequency', 'Monetary']\n",
    "\n",
    "# Apply the criteria\n",
    "customer_features['credit_risk'] = customer_features.apply(assign_credit_risk, axis=1)\n",
    "\n",
    "# Merge back to original data (if needed for transaction-level analysis)\n",
    "rfm_metrics = rfm_metrics.merge(customer_features[['CustomerId', 'credit_risk']], on='CustomerId', how='left')\n",
    "\n",
    "# Display results\n",
    "print(rfm_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048652d6",
   "metadata": {},
   "source": [
    "#Cluster Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c02df9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           CustomerId  Recency  Frequency  Monetary  Cluster  credit_risk\n",
      "0        CustomerId_1       -6          1  -10000.0        0            1\n",
      "1       CustomerId_10       -6          1  -10000.0        0            1\n",
      "2     CustomerId_1001       -1          5   20000.0        0            1\n",
      "3     CustomerId_1002      -64         11    4225.0        0            1\n",
      "4     CustomerId_1003      -78          6   20000.0        2            0\n",
      "...               ...      ...        ...       ...      ...          ...\n",
      "3737   CustomerId_992      -85          6   20000.0        2            0\n",
      "3738   CustomerId_993      -64          5   20000.0        2            0\n",
      "3739   CustomerId_994      -89        101  543873.0        2            0\n",
      "3740   CustomerId_996      -22         17  139000.0        0            1\n",
      "3741   CustomerId_998      -90         22  100000.0        2            0\n",
      "\n",
      "[3742 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "\n",
    "# Preprocess RFM features\n",
    "# Select RFM columns for clustering\n",
    "rfm_features = rfm_metrics[['Recency', 'Frequency', 'Monetary','credit_risk']]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "rfm_scaled = scaler.fit_transform(rfm_features)\n",
    "\n",
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "rfm_metrics['Cluster'] = kmeans.fit_predict(rfm_scaled)\n",
    "\n",
    "# Display results\n",
    "print(rfm_metrics[['CustomerId', 'Recency', 'Frequency', 'Monetary', 'Cluster','credit_risk']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae6f4a2",
   "metadata": {},
   "source": [
    "#Model Training and Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874405c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/30 15:28:04 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/06/30 15:28:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Best Params: {'C': 0.1, 'solver': 'lbfgs'}\n",
      "LogisticRegression Metrics: Accuracy=0.83, Precision=0.96, Recall=0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/30 15:28:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/06/30 15:28:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Best Params: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest Metrics: Accuracy=0.98, Precision=0.99, Recall=0.98\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# Features and target\n",
    "X = rfm_metrics[['Recency', 'Frequency', 'Monetary']]\n",
    "y = rfm_metrics['credit_risk']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define models and hyperparameter grids\n",
    "models = {\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(random_state=42),\n",
    "        'param_grid': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'solver': ['liblinear', 'lbfgs']\n",
    "        }\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'param_grid': {\n",
    "            'n_estimators': [50, 100],\n",
    "            'max_depth': [None, 10],\n",
    "            'min_samples_split': [2, 5]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# MLflow experiment tracking\n",
    "mlflow.set_experiment(\"Credit_Risk_Modeling\")\n",
    "\n",
    "for model_name, config in models.items():\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"test_size\", 0.2)\n",
    "        mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "        # Grid Search\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=config['model'],\n",
    "            param_grid=config['param_grid'],\n",
    "            cv=2,  # Small dataset, use 2-fold CV\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "\n",
    "        # Evaluate on test set\n",
    "        if len(X_test) > 0:  # Ensure test set is not empty\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "            recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        else:\n",
    "            accuracy, precision, recall = 0, 0, 0  # Handle small dataset case\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "\n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(best_model, f\"{model_name}_model\")\n",
    "\n",
    "        print(f\"{model_name} Best Params: {grid_search.best_params_}\")\n",
    "        print(f\"{model_name} Metrics: Accuracy={accuracy:.2f}, Precision={precision:.2f}, Recall={recall:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5ad0cd",
   "metadata": {},
   "source": [
    "# Unit Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "531f8144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           CustomerId  Recency  Frequency  Monetary  Cluster  credit_risk\n",
      "0        CustomerId_1       -6          1  -10000.0        0            1\n",
      "1       CustomerId_10       -6          1  -10000.0        0            1\n",
      "2     CustomerId_1001       -1          5   20000.0        0            1\n",
      "3     CustomerId_1002      -64         11    4225.0        0            1\n",
      "4     CustomerId_1003      -78          6   20000.0        2            0\n",
      "...               ...      ...        ...       ...      ...          ...\n",
      "3737   CustomerId_992      -85          6   20000.0        2            0\n",
      "3738   CustomerId_993      -64          5   20000.0        2            0\n",
      "3739   CustomerId_994      -89        101  543873.0        2            0\n",
      "3740   CustomerId_996      -22         17  139000.0        0            1\n",
      "3741   CustomerId_998      -90         22  100000.0        2            0\n",
      "\n",
      "[3742 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pytest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load data\n",
    "transaction_data = pd.read_csv(data_path)\n",
    "\n",
    "# RFM data - remove the print() statement\n",
    "\n",
    "df=rfm_metrics[['CustomerId', 'Recency', 'Frequency', 'Monetary', 'Cluster','credit_risk']]\n",
    "\n",
    "rfm_data = df[['CustomerId', 'Recency', 'Frequency', 'Monetary', 'Cluster', 'credit_risk']]\n",
    "\n",
    "# If you want to print it for viewing, do it separately\n",
    "print(rfm_data[['CustomerId', 'Recency', 'Frequency', 'Monetary', 'Cluster', 'credit_risk']])\n",
    "\n",
    "# Rename and merge\n",
    "rfm_data = rfm_data.rename(columns={'credit_risk': 'is_high_risk'})[['CustomerId', 'Recency', 'Frequency', 'Monetary', 'is_high_risk']]\n",
    "main_data = transaction_data.merge(rfm_data[['CustomerId', 'Recency', 'Frequency', 'Monetary', 'is_high_risk']], \n",
    "                                  on='CustomerId', how='left')\n",
    "\n",
    "# Rest of your test functions remain the same\n",
    "def test_data_integrity():\n",
    "    \"\"\"Test data for missing values and correct types.\"\"\"\n",
    "    assert not main_data[['Recency', 'Frequency', 'Monetary', 'is_high_risk']].isnull().any().any(), \"Data contains missing values\"\n",
    "    assert main_data['Recency'].dtype == int, \"Recency should be integer\"\n",
    "    assert main_data['Frequency'].dtype == int, \"Frequency should be integer\"\n",
    "    assert main_data['Monetary'].dtype == float, \"Monetary should be float\"\n",
    "    assert main_data['is_high_risk'].isin([0, 1]).all(), \"is_high_risk should be 0 or 1\"\n",
    "\n",
    "def test_data_merge():\n",
    "    \"\"\"Test if merge preserves all transactions.\"\"\"\n",
    "    assert len(main_data) == len(transaction_data), \"Merge should preserve all transactions\"\n",
    "    assert 'is_high_risk' in main_data.columns, \"is_high_risk column missing\"\n",
    "    assert main_data['CustomerId'].nunique() == rfm_data['CustomerId'].nunique(), \"Customer count mismatch after merge\"\n",
    "\n",
    "def test_data_split():\n",
    "    \"\"\"Test if train-test split maintains data integrity.\"\"\"\n",
    "    X = main_data[['Recency', 'Frequency', 'Monetary']]\n",
    "    y = main_data['is_high_risk']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    assert len(X_train) + len(X_test) == len(X), \"Train-test split size mismatch\"\n",
    "    assert len(y_train) + len(y_test) == len(y), \"Target split size mismatch\"\n",
    "\n",
    "def test_model_output():\n",
    "    \"\"\"Test if model produces valid predictions.\"\"\"\n",
    "    X = main_data[['Recency', 'Frequency', 'Monetary']]\n",
    "    y = main_data['is_high_risk']\n",
    "    model = LogisticRegression(random_state=42)\n",
    "    model.fit(X, y)\n",
    "    predictions = model.predict(X)\n",
    "    assert len(predictions) == len(y), \"Prediction length mismatch\"\n",
    "    assert set(predictions).issubset([0, 1]), \"Predictions should be 0 or 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e44f9d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/30 22:35:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/06/30 22:35:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Best Params: {'C': 0.1, 'solver': 'lbfgs'}\n",
      "LogisticRegression Metrics: Accuracy=0.83, Precision=0.96, Recall=0.71, F1=0.82, ROC-AUC=0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/30 22:35:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/06/30 22:35:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Best Params: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest Metrics: Accuracy=0.98, Precision=0.99, Recall=0.98, F1=0.99, ROC-AUC=1.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# RFM data - remove the print() statement\n",
    "\n",
    "df=rfm_metrics[['CustomerId', 'Recency', 'Frequency', 'Monetary', 'Cluster','credit_risk']]\n",
    "\n",
    "rfm_data = df[['CustomerId', 'Recency', 'Frequency', 'Monetary', 'Cluster', 'credit_risk']]\n",
    "\n",
    "# Features and target\n",
    "X = df[['Recency', 'Frequency', 'Monetary']]\n",
    "y = df['credit_risk']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define models and hyperparameter grids\n",
    "models = {\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(random_state=42),\n",
    "        'param_grid': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'solver': ['liblinear', 'lbfgs']\n",
    "        }\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'param_grid': {\n",
    "            'n_estimators': [50, 100],\n",
    "            'max_depth': [None, 10],\n",
    "            'min_samples_split': [2, 5]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# MLflow experiment tracking\n",
    "mlflow.set_experiment(\"Credit_Risk_Modeling\")\n",
    "\n",
    "for model_name, config in models.items():\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"test_size\", 0.2)\n",
    "        mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "        # Grid Search\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=config['model'],\n",
    "            param_grid=config['param_grid'],\n",
    "            cv=2,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "\n",
    "        # Evaluate on test set\n",
    "        if len(X_test) > 0:\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.predict_proba(X_test)[:, 1] if hasattr(best_model, 'predict_proba') else best_model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "            recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "            f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "            roc_auc = roc_auc_score(y_test, y_pred_proba) if len(np.unique(y_test)) > 1 else 0\n",
    "        else:\n",
    "            accuracy, precision, recall, f1, roc_auc = 0, 0, 0, 0, 0\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(best_model, f\"{model_name}_model\")\n",
    "\n",
    "        # Plot and log ROC curve (if test set exists and model supports probabilities)\n",
    "        if len(X_test) > 0 and hasattr(best_model, 'predict_proba'):\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "            plt.figure()\n",
    "            plt.plot(fpr, tpr, label=f\"{model_name} (AUC = {roc_auc:.2f})\")\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.xlabel(\"False Positive Rate\")\n",
    "            plt.ylabel(\"True Positive Rate\")\n",
    "            plt.title(f\"ROC Curve - {model_name}\")\n",
    "            plt.legend(loc=\"best\")\n",
    "            plt.savefig(f\"roc_curve_{model_name}.png\")\n",
    "            mlflow.log_artifact(f\"roc_curve_{model_name}.png\")\n",
    "            plt.close()\n",
    "\n",
    "        print(f\"{model_name} Best Params: {grid_search.best_params_}\")\n",
    "        print(f\"{model_name} Metrics: Accuracy={accuracy:.2f}, Precision={precision:.2f}, Recall={recall:.2f}, F1={f1:.2f}, ROC-AUC={roc_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2380d5a3",
   "metadata": {},
   "source": [
    "#Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5b8568f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading LogisticRegression model: Invalid value \"<logistic_run_id>\" for parameter 'run_id' supplied.\n",
      "Error loading RandomForest model: Invalid value \"<random_forest_run_id>\" for parameter 'run_id' supplied.\n"
     ]
    }
   ],
   "source": [
    "import mlflow.sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define rfm_metrics\n",
    "# RFM data \n",
    "\n",
    "df=rfm_metrics[['CustomerId', 'Recency', 'Frequency', 'Monetary', 'Cluster','credit_risk']]\n",
    "\n",
    "rfm_data = df[['CustomerId', 'Recency', 'Frequency', 'Monetary', 'Cluster', 'credit_risk']]\n",
    "\n",
    "# Features and target\n",
    "X = rfm_metrics[['Recency', 'Frequency', 'Monetary']]\n",
    "y = rfm_metrics['credit_risk']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Replace with actual run IDs from MLflow UI\n",
    "run_ids = {\n",
    "    'LogisticRegression': '<logistic_run_id>',\n",
    "    'RandomForest': '<random_forest_run_id>'\n",
    "}\n",
    "\n",
    "for model_name, run_id in run_ids.items():\n",
    "    try:\n",
    "        # Load model\n",
    "        model = mlflow.sklearn.load_model(f\"runs:/{run_id}/{model_name}_model\")\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else y_pred\n",
    "\n",
    "        # Compute metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba) if len(np.unique(y_test)) > 1 else 0\n",
    "\n",
    "        # Print results\n",
    "        print(f\"\\n{model_name} Metrics:\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        print(f\"Precision: {precision:.2f}\")\n",
    "        print(f\"Recall: {recall:.2f}\")\n",
    "        print(f\"F1 Score: {f1:.2f}\")\n",
    "        print(f\"ROC-AUC: {roc_auc:.2f}\")\n",
    "\n",
    "        # Plot ROC curve\n",
    "        if len(X_test) > 0 and hasattr(model, 'predict_proba'):\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "            plt.figure()\n",
    "            plt.plot(fpr, tpr, label=f\"{model_name} (AUC = {roc_auc:.2f})\")\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.xlabel(\"False Positive Rate\")\n",
    "            plt.ylabel(\"True Positive Rate\")\n",
    "            plt.title(f\"ROC Curve - {model_name}\")\n",
    "            plt.legend(loc=\"best\")\n",
    "            plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {model_name} model: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
